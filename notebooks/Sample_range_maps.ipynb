{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Sample IUCN range maps\n",
    "\n",
    "Samples a set of species from locally stored IUCN range maps and then samples random points to generate a set of presence and absence points.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "Species range data is held locally (could adapt to use IUCN Red List API).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Library import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, box, Polygon\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from EcoNameTranslator import EcoNameTranslator\n",
    "from EcoNameTranslator import ReverseTranslator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_species_subset(shapefile_path,feature_class = None, n_species_sample = 20):\n",
    "    # Load the shapefile using geopandas\n",
    "    if feature_class:\n",
    "        species_ranges = gpd.read_file(shapefile_path,layer = feature_class)\n",
    "    else:\n",
    "        species_ranges = gpd.read_file(shapefile_path)\n",
    "\n",
    "    print(\"Read species ranges\")\n",
    "    #select extant or possibly extant species where the 'PRESENCE' attribute is either 1 or 3\n",
    "    filtered_species_ranges = species_ranges[species_ranges['presence'].isin([1, 2, 3])]\n",
    "    print(\"Filtered for extant and possibly extant\")\n",
    "    filtered_species_ranges = filtered_species_ranges[filtered_species_ranges['seasonal'].isin([1, 2, 3])]\n",
    "    print(\"Filtered for seasonality - removing passage\")\n",
    "\n",
    "    # Randomly sample a subset of species ranges\n",
    "    if n_species_sample < len(species_ranges):\n",
    "        sampled_species_ranges = species_ranges.sample(n=n_species_sample, random_state=42)  # Set random_state for reproducibility\n",
    "    else:\n",
    "        sampled_species_ranges = species_ranges  # If n_species_sample exceeds the number of available ranges, take all ranges\n",
    "    \n",
    "    print(\"Sampled points\")\n",
    "\n",
    "    # Join polygons with the same 'BINOMIAL' (species name) together\n",
    "    if 'binomial' in sampled_species_ranges.columns:\n",
    "        sampled_species_ranges = sampled_species_ranges.dissolve(by='binomial')\n",
    "    elif 'sci_name' in sampled_species_ranges.columns:\n",
    "        sampled_species_ranges = sampled_species_ranges.dissolve(by='sci_name')\n",
    "        sampled_species_ranges.rename(columns={'sci_name':'binomial'})\n",
    "    print(\"Dissolved ranges\")\n",
    "    return sampled_species_ranges\n",
    "\n",
    "\n",
    "# Create a function to randomly generate points within the bounding box\n",
    "def generate_random_point_within_bbox(bbox):\n",
    "    minx, miny, maxx, maxy = bbox\n",
    "    x = random.uniform(minx, maxx)\n",
    "    y = random.uniform(miny, maxy)\n",
    "    return Point(x, y)\n",
    "\n",
    "def sample_points_presence_absence(species_range,bounds, n_presence = 10,n_absence = 10):\n",
    "    # Sample points and classify them as presence/absence\n",
    "    #n_points = 1000  # Number of points to sample\n",
    "\n",
    "    points = []\n",
    "    presence_absence = []\n",
    "\n",
    "    presences = species_range.sample_points(size = n_presence)\n",
    "\n",
    "    # Create the inverse polygon (area outside the species range within the bounding box)\n",
    "    bbox_polygon = box(*bounds)\n",
    "    inverse_polygon = bbox_polygon.difference(species_range.geometry)\n",
    "    #print(type(inverse_polygon))\n",
    "    #absence_range_gdf = gpd.GeoSeries(inverse_polygon, crs=species_range.crs)\n",
    "\n",
    "    absences = inverse_polygon.sample_points(size = n_absence)\n",
    "    \n",
    "    pdf = presences.get_coordinates()\n",
    "    pdf['presence'] = np.ones(pdf.shape[0])\n",
    "\n",
    "\n",
    "    adf = absences.get_coordinates()\n",
    "    adf['presence'] = np.zeros(adf.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "    return pd.concat([adf,pdf],axis = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a id='Read subset of species'></a>\n",
    "## Read species \n",
    "\n",
    "Read species shapefile/gdb and extract a subset of the species \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read species ranges\n",
      "Filtered for extant and possibly extant\n",
      "Filtered for seasonality - removing passage\n",
      "Sampled points\n",
      "Dissolved ranges\n"
     ]
    }
   ],
   "source": [
    "#Mammals\n",
    "# define the mammals shapefile\n",
    "mammal_shapefile_path = \"/mnt/c/Users/mikeha/Work/Spatial data/Red List/2022/MAMMALS/MAMMALS.shp\"\n",
    "mammal_subset = read_species_subset(mammal_shapefile_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read species ranges\n",
      "Filtered for extant and possibly extant\n",
      "Filtered for seasonality - removing passage\n",
      "Sampled points\n",
      "Dissolved ranges\n"
     ]
    }
   ],
   "source": [
    "reptile_shapefile_path = \"/mnt/c/Users/mikeha/Work/Spatial data/Red List/2022/REPTILES/REPTILES.shp\"\n",
    "reptile_subset = read_species_subset(reptile_shapefile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read species ranges\n",
      "Filtered for extant and possibly extant\n",
      "Filtered for seasonality - removing passage\n",
      "Sampled points\n",
      "Dissolved ranges\n"
     ]
    }
   ],
   "source": [
    "amphibian_shapefile_path = \"/mnt/c/Users/mikeha/Work/Spatial data/Red List/2022/AMPHIBIANS/AMPHIBIANS.shp\"\n",
    "amphibian_subset = read_species_subset(amphibian_shapefile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read species ranges\n",
      "Filtered for extant and possibly extant\n",
      "Filtered for seasonality - removing passage\n",
      "Sampled points\n",
      "Dissolved ranges\n"
     ]
    }
   ],
   "source": [
    "bird_shapefile_path = \"/mnt/c/Users/mikeha/Work/Spatial data/Red List/2022/Birds/batch_1.shp\"\n",
    "bird_subset = read_species_subset(bird_shapefile_path)\n",
    "bird_subset.index.names = ['binomial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a id='Sample points'></a>\n",
    "## Sample points for presences/absences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_p_a_points(subset):\n",
    "    bounds = subset.total_bounds  # [minx, miny, maxx, maxy]\n",
    "\n",
    "    all_df_pa = None\n",
    "    for i in range(subset.shape[0]):\n",
    "        s_df_pa = sample_points_presence_absence(subset.iloc[[i]],bounds)\n",
    "        if all_df_pa is None:\n",
    "            all_df_pa = s_df_pa\n",
    "        else:\n",
    "            all_df_pa = pd.concat([all_df_pa,s_df_pa])\n",
    "    \n",
    "    return all_df_pa\n",
    "\n",
    "\n",
    "def get_common_names(scientific_names):\n",
    "    translator = ReverseTranslator()\n",
    "    common_names = translator.translate(scientific_names)\n",
    "    list_common_names = []\n",
    "    for binomial in scientific_names:\n",
    "        if len(common_names[binomial][1]) > 0:\n",
    "            list_common_names.append(common_names[binomial][1][0])\n",
    "        else:\n",
    "            list_common_names.append(\"\")\n",
    "\n",
    "    return list_common_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginnging name reformatting\n",
      "Name reformatting complete\n",
      "Validating scientific names\n",
      "Expanding higher level taxonomic names\n",
      "Trying common name translation...(this may take a while)\n"
     ]
    }
   ],
   "source": [
    "mammal_points = construct_p_a_points(mammal_subset)\n",
    "mammal_points['common'] = get_common_names(scientific_names=mammal_points.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginnging name reformatting\n",
      "Name reformatting complete\n",
      "Validating scientific names\n",
      "Expanding higher level taxonomic names\n",
      "Trying common name translation...(this may take a while)\n"
     ]
    }
   ],
   "source": [
    "reptile_points = construct_p_a_points(reptile_subset)\n",
    "reptile_points['common'] = get_common_names(scientific_names=reptile_points.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginnging name reformatting\n",
      "Name reformatting complete\n",
      "Validating scientific names\n",
      "Expanding higher level taxonomic names\n",
      "Trying common name translation...(this may take a while)\n"
     ]
    }
   ],
   "source": [
    "amphibian_points = construct_p_a_points(amphibian_subset)\n",
    "amphibian_points['common'] = get_common_names(amphibian_points.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginnging name reformatting\n",
      "Name reformatting complete\n",
      "Validating scientific names\n",
      "Expanding higher level taxonomic names\n",
      "Trying common name translation...(this may take a while)\n"
     ]
    }
   ],
   "source": [
    "bird_points = construct_p_a_points(bird_subset)\n",
    "bird_points['common'] = get_common_names(bird_points.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deal with any missing common names\n",
    "def find_empty_common_names(points):\n",
    "    return np.unique(points.iloc[np.where(points['common'] == \"\")[0]].index.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_empty_common_names(mammal_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Aipysurus mosaicus', 'Aristelliger praesignis',\n",
       "       'Calotes bhutanensis', 'Cyrtodactylus srilekhae',\n",
       "       'Cyrtodactylus wallacei', 'Hebius sarawacensis',\n",
       "       'Hemidactylus mindiae', 'Homopholis fasciata',\n",
       "       'Lamprophis erlangeri', 'Liolaemus ceii', 'Liolaemus isabelae',\n",
       "       'Phalotris mertensi', 'Plestiodon japonicus'], dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_empty_common_names(reptile_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    'Aipysurus mosaicus':'mosaic sea snake',\n",
    "    'Aristelliger praesignis':'croaking lizard',\n",
    "       'Calotes bhutanensis':'Bhutan Beaty Lizard',\n",
    "       'Cyrtodactylus srilekhae': 'Bangalore Geckoella',\n",
    "       'Cyrtodactylus wallacei':'South Sulawesi Bent-toed Gecko',\n",
    "       'Hebius sarawacensis':'Sarawak Keelback',\n",
    "       'Hemidactylus mindiae':'Mount Sinai Gecko',\n",
    "       'Homopholis fasciata':'Banded Velvet Gecko',\n",
    "       'Lamprophis erlangeri':'Ethiopian House Snake',\n",
    "       'Liolaemus ceii':'Ceis Tree Iguana',\n",
    "       'Liolaemus isabelae':'Isabels Tree Iguana',\n",
    "       'Phalotris mertensi':'Coral-Falsa',\n",
    "       'Plestiodon japonicus':'Japanese skink'\n",
    "}\n",
    "\n",
    "for binomial in replacements:\n",
    "    reptile_points.loc[binomial,'common'] = replacements[binomial]\n",
    "\n",
    "#Check no empty common names\n",
    "find_empty_common_names(reptile_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ameerega yoshina', 'Ansonia minuta', 'Austrochaperina polysticta',\n",
       "       'Bolitoglossa vallecula', 'Laliostoma labrosum',\n",
       "       'Leptobrachella picta', 'Limnonectes gyldenstolpei',\n",
       "       'Limnonectes ingeri', 'Litoria multicolor', 'Litoria singadanae',\n",
       "       'Megophrys palpebralespinosa', 'Proceratophrys bigibbosa',\n",
       "       'Rana japonica', 'Scutiger boulengeri', 'Speleomantes supramontis',\n",
       "       'Xenorhina macrops'], dtype=object)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_empty_common_names(amphibian_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacements = {\n",
    "    'Ameerega yoshina':'poison dart frog',\n",
    "    'Ansonia minuta':'Tiny Stream Toad',\n",
    "    'Austrochaperina polysticta':'Morobe Land Frog',\n",
    "    'Bolitoglossa vallecula':'Yarmal Mushroom-tongue Salamander',\n",
    "    'Laliostoma labrosum':'Madagascar Bullfrog',\n",
    "    'Leptobrachella picta':'Painted Slender Litter Frog',\n",
    "    'Limnonectes gyldenstolpei':'Capped Frog',\n",
    "    'Limnonectes ingeri':'Ingers Wart Frog',\n",
    "    'Litoria multicolor':'Multi-coloured Tree Frog',\n",
    "    'Litoria singadanae':'Green tree frog',\n",
    "    'Megophrys palpebralespinosa':'Rough-skinned Horned Toad',\n",
    "    'Proceratophrys bigibbosa':'Peters Smooth Horned Frog',\n",
    "    'Rana japonica':'Japanese brown frog',\n",
    "    'Scutiger boulengeri':'Xizang Alpine Toad',\n",
    "    'Speleomantes supramontis':'Supramonte Cave Salamander',\n",
    "    'Xenorhina macrops':'Hellwig Fanged Frog'\n",
    "}\n",
    "\n",
    "for binomial in replacements:\n",
    "    amphibian_points.loc[binomial,'common'] = replacements[binomial]\n",
    "\n",
    "#Check no empty common names\n",
    "find_empty_common_names(amphibian_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Calliope obscura', 'Hydrobates hornbyi'], dtype=object)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_empty_common_names(bird_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacements = {\n",
    "    'Calliope obscura':'black-throated robin',\n",
    "    'Hydrobates hornbyi':'Ringed storm petrel'\n",
    "}\n",
    "\n",
    "for binomial in replacements:\n",
    "    bird_points.loc[binomial,'common'] = replacements[binomial]\n",
    "\n",
    "#Check no empty common names\n",
    "find_empty_common_names(bird_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_pa = pd.concat([mammal_points, reptile_points, amphibian_points, bird_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_pa['x'] = np.round(all_df_pa['x'],decimals = 2)\n",
    "all_df_pa['y'] = np.round(all_df_pa['y'],decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the dataframe to file\n",
    "all_df_pa.to_csv('../eval/species_point_presence_absence.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a id='conclusion'></a>\n",
    "## Conclusion\n",
    "\n",
    "{ Summarize findings and next steps. }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
